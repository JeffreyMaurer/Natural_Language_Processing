{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model (HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace words with word buckets\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import OrderedDict, Counter\n",
    "import itertools as it\n",
    "from functools import reduce \n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_json('../data/Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "data[['headline','is_sarcastic']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove upper case, weird white space and punctuation\n",
    "data['headline'] = data['headline'].apply(lambda x: x.lower())\n",
    "data['headline'] = data['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data[['headline','is_sarcastic']].head()\n",
    "data = data[['headline','is_sarcastic']]\n",
    "x, y = (data['headline'].values, data['is_sarcastic'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28406"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our entire dictionary of words\n",
    "c=Counter(\" \".join(x).split(\" \")) \n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words missing from the sarcastic dictionary:  7557 \n",
      "\n",
      "Most common sarcastic words:  [('to', 4145), ('of', 3132), ('in', 1757), ('for', 1419), ('on', 1056), ('man', 1032), ('with', 855), ('new', 839), ('the', 651), ('by', 581), ('from', 561), ('at', 546), ('a', 525), ('area', 477), ('out', 468), ('up', 430), ('report', 426), ('about', 410), ('after', 383), ('it', 383)] \n",
      "\n",
      "Most common words unique to the serious dictionary:  [('huffpost', 58), ('queer', 54), ('trans', 49), ('kardashian', 47), ('jenner', 40), ('lgbt', 40), ('lgbtq', 32), ('roundup', 32), ('instagram', 30), ('trevor', 30), ('noah', 29), ('funniest', 28), ('schumer', 27), ('kimmel', 25), ('huffpollster', 24), ('hill', 24), ('chrissy', 22), ('veterans', 21), ('uk', 21), ('conservatives', 21)] \n",
      "\n",
      "Number of singletons in the sarcastic dictionary:  9895\n"
     ]
    }
   ],
   "source": [
    "# Characterization of the two classes, the first is sarcastic\n",
    "csarcastic=Counter(\" \".join(x[y==1]).split(\" \"))\n",
    "print(\"Words missing from the sarcastic dictionary: \", len(x)-len(csarcastic),\"\\n\")\n",
    "print(\"Most common sarcastic words: \", csarcastic.most_common(20),\"\\n\")\n",
    "unique_serious = [word for word in c.most_common() if word[0] not in csarcastic]\n",
    "print(\"Most common words unique to the serious dictionary: \", unique_serious[:20],\"\\n\")\n",
    "singleton_sarcastic = [word[0] for word in csarcastic.most_common() if word[1]==1]\n",
    "print(\"Number of singletons in the sarcastic dictionary: \", len(singleton_sarcastic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words missing from the serious dictionary:  7656 \n",
      "\n",
      "Most common serious words:  [('the', 4741), ('to', 4074), ('a', 2475), ('of', 2472), ('in', 2429), ('for', 1886), ('and', 1659), ('is', 1508), ('on', 1336), ('trump', 1046), ('with', 946), ('you', 779), ('this', 704), ('new', 677), ('from', 664), ('how', 649), ('about', 646), ('at', 645), ('your', 576), ('are', 563)] \n",
      "\n",
      "Most common words unique to the sarcastic dictionary:  [('fucking', 67), ('shit', 61), ('clearly', 43), ('fuck', 42), ('unable', 33), ('realizes', 33), ('archives', 33), ('recommends', 28), ('per', 27), ('asshole', 26), ('currently', 25), ('relieved', 21), ('unsure', 20), ('recommend', 18), ('remaining', 17), ('capable', 16), ('panicked', 15), ('frantically', 15), ('shitty', 15), ('stares', 15)] \n",
      "\n",
      "Number of singletons in the sarcastic dictionary:  9592\n"
     ]
    }
   ],
   "source": [
    "cserious=Counter(\" \".join(x[y==0]).split(\" \"))\n",
    "print(\"Words missing from the serious dictionary: \",len(x)-len(cserious),\"\\n\")\n",
    "print(\"Most common serious words: \", cserious.most_common(20),\"\\n\")\n",
    "unique_sarcastic = [word for word in c.most_common() if word[0] not in cserious]\n",
    "print(\"Most common words unique to the sarcastic dictionary: \", unique_sarcastic[:20],\"\\n\")\n",
    "singleton_serious = [word[0] for word in cserious.most_common() if word[1]==1]\n",
    "print(\"Number of singletons in the sarcastic dictionary: \", len(singleton_serious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of the top words\n",
    "top=list(it.chain(*c.most_common(1000)))[::2] \n",
    "# How many headlines only have those words?\n",
    "only=[all([(word in top) for word in data['headline'][i].split(\" \")]) for i in range(len(data))]\n",
    "sum(only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data=data[only]\n",
    "small_data.head()\n",
    "# We shall split the input and output into two np arrays\n",
    "x, y = (small_data['headline'].values, small_data['is_sarcastic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csmall=Counter(\" \".join(x).split(\" \"))\n",
    "smalltop=list(it.chain(*csmall.most_common(1000)))[::2] # get a list of the top words\n",
    "numwords=len(smalltop)\n",
    "numwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['name', 'is', 'his', 'my', 'not', 'dogs', 'sam', 'jerry', 'john', 'jeff', 'simon']\n"
     ]
    }
   ],
   "source": [
    "# We need to test and make sure that this method works on a toy example\n",
    "x = [\"my name is sam\", \"my name is not jerry\", 'his name is john', 'his dogs name is jeff', 'his dogs name is not simon']\n",
    "ctest=Counter(\" \".join(x).split(\" \"))\n",
    "smalltest=list(it.chain(*ctest.most_common()))[::2] # get a list of the top words\n",
    "numwords=len(smalltest)\n",
    "print(numwords)\n",
    "print(smalltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n",
      " [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001]]\n"
     ]
    }
   ],
   "source": [
    "# Produce the transition matrix\n",
    "embedding={word:i for i, word in enumerate(smalltest)}\n",
    "test_matrix=np.zeros((numwords+1,numwords+1))+0.001\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,headline in enumerate(x):\n",
    "    which = test_matrix\n",
    "    prev = numwords\n",
    "    for word in headline.split(\" \"):\n",
    "        which[prev, embedding[word]] += 1\n",
    "        prev = embedding[word]\n",
    "    which[prev, numwords] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'is', 'his', 'my', 'not', 'dogs', 'sam', 'jerry', 'john', 'jeff', 'simon']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 5., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 2., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
       "       [2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 3., 2., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(smalltest)\n",
    "np.round(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.4, 0. , 0.2, 0. , 0.2, 0.2, 0. , 0. ],\n",
       "       [0.3, 0. , 0. , 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0. ],\n",
       "       [1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0.6, 0.4, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the two np arrays into probability rows\n",
    "normalize = lambda x: x/np.sum(x,1,keepdims=True)\n",
    "test_matrix = normalize(test_matrix)\n",
    "np.round(test_matrix,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this works, each row should add up to 1.\n",
    "Each row corresponds to a word, and each value in that row corresponds to the frequency of the word associated with that column to come after it. The last row represents the beginning of a statement, not a word. The last column represents the end of a statement, not a word either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " his dogs name is not simon\n",
      " my name is not jerry\n",
      " his name is sam\n",
      " his name is jeff\n",
      " my name is jeff\n",
      " his name is not simon\n",
      " his dogs name is not jerry\n",
      " his dogs name is not jerry\n",
      " my name is john\n",
      " his dogs name is john\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    end = numwords\n",
    "    word = int(np.random.choice(np.arange(numwords+1),1,p=test_matrix[numwords,]))\n",
    "    headline = ''\n",
    "    while word != end:\n",
    "        # append the word\n",
    "        headline = headline + \" \" + smalltest[word] \n",
    "        # get word index, it's originally a 1-size list, not int\n",
    "        word = int(np.random.choice(np.arange(numwords+1),1,p=test_matrix[word,]))\n",
    "    print(headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19152\n",
      "278\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "# Get the word list for the sarcastic\n",
    "print(len(csarcastic))\n",
    "# get a list of the top words\n",
    "top=list(it.chain(*csarcastic.most_common(1000)))[::2] \n",
    "# How many headlines only have those words?\n",
    "x, y = (data['headline'].values, data['is_sarcastic'].values)\n",
    "only = [all([(word in top) for word in x[i].split(\" \")]) for i in range(len(data))]\n",
    "print(sum(only)) # How many sentences only contain sarcastic words\n",
    "print(sum(only&y)) # How many sentences are sarcastic and only contain sarcastic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_data=data[np.logical_and(only,y)]\n",
    "sarcastic_data.head()\n",
    "# We shall split the input and output into two np arrays\n",
    "xsarcastic, ysarcastic = (sarcastic_data['headline'].values, sarcastic_data['is_sarcastic'].values)\n",
    "len(xsarcastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n"
     ]
    }
   ],
   "source": [
    "# Produce the transition matrix and embedding\n",
    "embed = lambda counter: {word[0]:i for i, word in enumerate(counter)}\n",
    "csmall_sarcastic = Counter(\" \".join(xsarcastic).split(\" \"))\n",
    "# This embedding is string:int\n",
    "sarcastic_embedding = embed(csmall_sarcastic.most_common())\n",
    "# This is just a list of the words\n",
    "sarcastic_words = list(it.chain(*csmall_sarcastic.most_common()))[::2] \n",
    "print(len(sarcastic_embedding))\n",
    "numwords = len(sarcastic_embedding)\n",
    "sarcastic_matrix = np.zeros((numwords+1,numwords+1))+0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_HMM(headlines, matrix, embedding):\n",
    "    \"\"\"\n",
    "    This function will in-place train an HMM transition matrix\n",
    "    params:\n",
    "        headlines: pandas dataframe of string sentences\n",
    "        matrix: an empty numpy matrix that has a row and column for each word plus another one for the end and start tokens\n",
    "        embedding: a dictionary from words to unique integer values\n",
    "    output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    numwords = len(embedding)\n",
    "    for i,headline in enumerate(headlines):\n",
    "        prev = numwords\n",
    "        for word in headline.split(\" \"):\n",
    "            matrix[prev, embedding[word]] += 1\n",
    "            prev = embedding[word]\n",
    "        matrix[prev, numwords] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e-03, 1.0000e-03, 1.0000e-03, 2.0010e+00],\n",
       "       [1.0000e-03, 1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
       "       [1.3001e+01, 1.0000e-03, 1.0000e-03, 1.0000e-03],\n",
       "       [1.0000e-03, 1.0000e-03, 1.0000e-03, 1.0000e-03]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_HMM(xsarcastic, sarcastic_matrix, sarcastic_embedding)\n",
    "sarcastic_matrix[1:5,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the np array into probability rows\n",
    "normalize = lambda x: x/np.sum(x,1,keepdims=True)\n",
    "sarcastic_matrix = normalize(sarcastic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_headline(matrix, corpus):\n",
    "    \"\"\"\n",
    "    A function to generate headlines given a word transition matrix and a corpus\n",
    "    params:\n",
    "        matrix: numpy matrix of word transition proportions. The last row and column refer to the start and end of headline tokens\n",
    "        corpus: a python list of all words in the corpus. The words should be in the same order as for the matrix\n",
    "    output:\n",
    "        headline: a string that is our generated headline\n",
    "    \"\"\"\n",
    "    numwords = matrix.shape[1]-1\n",
    "    end = numwords\n",
    "    word = int(np.random.choice(np.arange(numwords+1),1,p=matrix[numwords,]))\n",
    "    headline = ''\n",
    "    while word != end:\n",
    "        # append the word\n",
    "        headline = headline + \" \" + corpus[word]\n",
    "        # get word index, it's originally returned as a 1-size list, so we must convert to int\n",
    "        word = int(np.random.choice(np.arange(numwords+1),1,p=matrix[word,])) \n",
    "    return(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's generate the headlines\n",
    "num_gen = 1000\n",
    "sarcastic_headlines = [generate_headline(sarcastic_matrix, sarcastic_words) for _ in range(num_gen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have headlines, let's see if our classifiers can deal recognize it\n",
    "from Simple_Classifiers import run_algorithm, NB, NB_rank, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report well here we go right for help</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pope francis admits god debate desk doesnt ha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>royal baby has pretty sure he goes to see a p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breaking still nothing unveils president bush...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>area man in his life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0              report well here we go right for help           1.0\n",
       "1   pope francis admits god debate desk doesnt ha...           1.0\n",
       "2   royal baby has pretty sure he goes to see a p...           1.0\n",
       "3   breaking still nothing unveils president bush...           1.0\n",
       "4                               area man in his life           1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_test = pd.DataFrame({'headline':sarcastic_headlines, 'is_sarcastic':np.ones(num_gen)})\n",
    "sarcastic_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix, duration = run_algorithm(data, sarcastic_test, NB)\n",
    "acc = accuracy(confusion_matrix)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that around 80% of the time, the classifier can correctly classify these generated strings. Let's compare that to using the entire data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607642442852269"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix, duration = run_algorithm(data, data[data['is_sarcastic']==1], NB)\n",
    "acc = accuracy(confusion_matrix)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the entire data to train on, 96% of the sarcastic headlines are correctly classified. This does not compare favorable to the 80% accuracy of the generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's continue this thread and perform the same operation on the serious examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19053\n",
      "401\n",
      "367\n"
     ]
    }
   ],
   "source": [
    "# Get the word list for the serious\n",
    "print(len(cserious))\n",
    "# get a list of the top words\n",
    "top=list(it.chain(*cserious.most_common(1000)))[::2] \n",
    "# How many headlines only have those words?\n",
    "x, y = (data['headline'].values, data['is_sarcastic'].values)\n",
    "only = [all([(word in top) for word in x[i].split(\" \")]) for i in range(len(data))]\n",
    "print(sum(only)) # How many sentences only contain serious words\n",
    "print(sum(only&(y==0))) # How many sentences are serious and only contain serious words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serious_data=data[np.logical_and(only,y==0)]\n",
    "serious_data.head()\n",
    "# We shall split the input and output into two np arrays\n",
    "xserious, yserious = (serious_data['headline'].values, serious_data['is_sarcastic'].values)\n",
    "len(xserious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    }
   ],
   "source": [
    "# Produce the transition matrix and embedding\n",
    "csmall_serious = Counter(\" \".join(xserious).split(\" \"))\n",
    "# This embedding is string:int\n",
    "serious_embedding = embed(csmall_serious.most_common())\n",
    "# This is just a list of the words\n",
    "serious_words = list(it.chain(*csmall_serious.most_common()))[::2] \n",
    "print(len(serious_embedding))\n",
    "numwords = len(serious_embedding)\n",
    "serious_matrix = np.zeros((numwords+1,numwords+1))+0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e-03, 3.001e+00, 1.000e-03, 1.000e-03],\n",
       "       [1.000e-03, 1.000e-03, 1.000e-03, 1.000e-03],\n",
       "       [1.000e-03, 1.000e-03, 1.000e-03, 1.000e-03],\n",
       "       [1.000e-03, 1.001e+00, 1.000e-03, 1.000e-03]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_HMM(xserious, serious_matrix, serious_embedding)\n",
    "serious_matrix[1:5,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the np array into probability rows\n",
    "serious_matrix = normalize(serious_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's generate the serious headlines\n",
    "serious_headlines = [generate_headline(serious_matrix, serious_words) for _ in range(num_gen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>power party in washington</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why chinese parents this incredible reason pe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11 life change climate change climate talks</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our wish you happy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago on health care bill refugees but this...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0                          power party in washington           0.0\n",
       "1   why chinese parents this incredible reason pe...           0.0\n",
       "2        11 life change climate change climate talks           0.0\n",
       "3                                 our wish you happy           0.0\n",
       "4   chicago on health care bill refugees but this...           0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serious_test = pd.DataFrame({'headline':serious_headlines, 'is_sarcastic':np.zeros(num_gen)})\n",
    "serious_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix, duration = run_algorithm(data, serious_test, NB)\n",
    "acc = accuracy(confusion_matrix)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648314981648315"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix, duration = run_algorithm(data, data[data['is_sarcastic']==0], NB)\n",
    "acc = accuracy(confusion_matrix)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the generator is even worse at producing serious headlines. The generator only makes 1 out of 1000 headlines to be actually taken as serious. This is compared to the overall data where validation on the entire serious data yields 96% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
