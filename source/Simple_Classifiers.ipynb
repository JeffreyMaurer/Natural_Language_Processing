{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import itertools as it\n",
    "from functools import reduce \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, k):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        data: This should be a pandas data frame\n",
    "        k: This is an int indicating the folds of the data to be performed\n",
    "           If k is 0, perform LOO cross-validation: TODO\n",
    "           If k is 1, the data is both test and train\n",
    "    output:\n",
    "        train: This is a pandas data frame\n",
    "        test: This is a pandas data frame\n",
    "        cross: This is which kth fold that we have just yielded\n",
    "    \"\"\"\n",
    "    if k == 1:\n",
    "        yield(data, data, k)\n",
    "        return()\n",
    "    if k == 0: # TODO: double check\n",
    "        for i, value in enumerate(data):\n",
    "            train = data[:i].append(data[(i+1):])\n",
    "            test = data[i:(i+1)]\n",
    "            yield(train, test, i)\n",
    "    size = len(data)\n",
    "    for cross in range(k):\n",
    "        start = int(cross*size/k)\n",
    "        stop = int((cross+1)*size/k)\n",
    "        train = data[:start].append(data[stop:])\n",
    "        test = data[start:stop]\n",
    "        yield(train,test,cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(train, test, algorithm):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        train: a pandas data frame of the data\n",
    "        test: a pandas data frame of the data\n",
    "        algorithm: a pointer to a function that takes in data and outputs predictions\n",
    "        #   params:\n",
    "        #       data: a pandas dataframe\n",
    "        #       info: information from training. If not present, train the model\n",
    "        #   outputs:\n",
    "        #       values: if training, it will output the parameters learned during training\n",
    "        #               if testing, it will output the confusion_matrix\n",
    "    outputs:\n",
    "        confusion_matrix: The confusion matrix of the boolean classification\n",
    "        duration: The amount of time that this took to run\n",
    "        training_info: The necessary information to just run the algorithm without training again\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    training_info = algorithm(train)\n",
    "    confusion_matrix = algorithm(test, training_info)\n",
    "    duration = time.time() - start\n",
    "    return(confusion_matrix, duration, training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        confusion_matrix: a dictionary where entries are of the form {(T/F,T/F):freq}\n",
    "                          freq is the occurence of that prediction outcome\n",
    "    ouputs:\n",
    "        The output is a float between 0 and 1 indicating the overall accuracy of the \\\n",
    "        model given the binary confusion matrix.\n",
    "    \"\"\"\n",
    "    correct = confusion_matrix[(True, True)]+confusion_matrix[(False, False)]\n",
    "    return(correct/sum(list(confusion_matrix.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_term(dicto, word, sarcasm):\n",
    "        if not word in dicto:\n",
    "            dicto[word] = [0,0]\n",
    "            dicto[word][sarcasm] = 1  #if this is the first time we see the word, make its count the step\n",
    "        else:\n",
    "            dicto[word][sarcasm] += 1 #increment the count with another sighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(data,info=None):\n",
    "    values = None\n",
    "    if info is None:\n",
    "        prior=sum(data['is_sarcastic'])/len(data)\n",
    "        values = prior\n",
    "    else:\n",
    "        answer = 0\n",
    "        # If 1 is more common than 0, guess 1.\n",
    "        if info > 0.5:\n",
    "            answer = 1\n",
    "        confusion_matrix = {x:0 for x in it.product([0,1],repeat=2)}\n",
    "        for x in data['is_sarcastic']:\n",
    "            confusion_matrix[(answer,x)] += 1\n",
    "        values = confusion_matrix\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(data,info=None):\n",
    "    values = None\n",
    "    counts = {}\n",
    "    if info is None:\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            for word in entry.split(\" \"):\n",
    "                add_term(counts, word, sarc)\n",
    "        v=list(it.chain(*list(counts.values())))\n",
    "        num_serious_words=sum(v[0::2])\n",
    "        num_sarcastic_words=sum(v[1::2])\n",
    "        for word in counts:\n",
    "            counts[word][0] /= num_serious_words\n",
    "            counts[word][1] /= num_sarcastic_words\n",
    "        values = counts\n",
    "    else:\n",
    "        confusion_matrix = {x:0 for x in it.product([0,1],repeat=2)}\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            # For every headline, multiply the frequency of each word for each class\n",
    "            # If a word in the test set is not found in the training set, ignore it\n",
    "            r = list(it.chain(*[info.get(word, [1,1]) for word in entry.split(\" \")]))\n",
    "            p_serious = reduce((lambda x, y: x * y), r[0::2]) \n",
    "            p_sarcasm = reduce((lambda x, y: x * y), r[1::2]) \n",
    "            result=(p_serious < p_sarcasm, bool(sarc))\n",
    "            confusion_matrix[result] += 1\n",
    "        values = confusion_matrix\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_rank(data,info=None):\n",
    "    values = None\n",
    "    counts = {}\n",
    "    if info is None:\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            for word in entry.split(\" \"):\n",
    "                add_term(counts, word, sarc)\n",
    "        # Get the ranks of each word in reference to serious\n",
    "        ordered_counts_ser=OrderedDict(sorted(counts.items(), reverse=True, key=lambda x: x[1][0]))\n",
    "        for i,count in enumerate(ordered_counts_ser):\n",
    "            ordered_counts_ser[count][0]=i\n",
    "        # Get the ranks of each word in reference to sarcasm\n",
    "        ordered_counts_sarc=OrderedDict(sorted(ordered_counts_ser.items(), reverse=True, key=lambda x: x[1][1]))\n",
    "        for i,count in enumerate(ordered_counts_sarc):\n",
    "            ordered_counts_sarc[count][1]=i\n",
    "        values = ordered_counts_sarc\n",
    "    else:\n",
    "        confusion_matrix = {x:0 for x in it.product([0,1],repeat=2)}\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            # If a word in the test set is not found in the training set, ignore it\n",
    "            r=list(it.chain(*[info.get(word,[0,0]) for word in entry.split(\" \")]))\n",
    "            # For every headline, add up the rankings of each word for each class\n",
    "            psar = sum(r[1::2])\n",
    "            pser = sum(r[0::2])\n",
    "            result=(pser > psar,bool(sarc))\n",
    "            confusion_matrix[result] += 1\n",
    "        values = confusion_matrix\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Test the Classifiers!\n",
    "\n",
    "### Let's Get the Data First"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next couple parts are borrowed from work by Tanumoy Nandy at https://www.kaggle.com/tanumoynandy/sarcasm-detection-lstm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_json('../data/Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "data[['headline','is_sarcastic']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sarcasm vs Non-sarcasm')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get prior proportions\n",
    "sns.countplot(data.is_sarcastic)\n",
    "plt.xlabel('Label')\n",
    "plt.title('Sarcasm vs Non-sarcasm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the roseanne revival catches up to our thorny ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear sons web series closest t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen not come up ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jk rowling wishes snape happy birthday in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret bl...             0\n",
       "1  the roseanne revival catches up to our thorny ...             0\n",
       "2  mom starting to fear sons web series closest t...             1\n",
       "3  boehner just wants wife to listen not come up ...             1\n",
       "4  jk rowling wishes snape happy birthday in the ...             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove upper case, weird white space and punctuation\n",
    "data['headline'] = data['headline'].apply(lambda x: x.lower())\n",
    "data['headline'] = data['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "data[['headline','is_sarcastic']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I shall try to classify headlines myself. I shall take a group of 30 headlines and assign them sarcastic or not sarcastic. This will act as a baseline for any algorithms we test. If any of the the classification schemes perform better than I do, we will consider it as performing at superhuman levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hillary clinton loses lead over bernie sanders in new iowa poll\n",
      "\n",
      "several women accuse progressive media executive don hazen of sexual harassment\n",
      "\n",
      "success and still enjoying your 'happy place'\n",
      "\n",
      "last 12 years a real wake-up call for area man\n",
      "\n",
      "pollsters admit they underestimated voters' adrenal glands\n",
      "\n",
      "lin-manuel miranda freestyles about life's most annoying minor inconveniences on 'ellen'\n",
      "\n",
      "john lewis won't attend civil rights museum opening because trump is going\n",
      "\n",
      "is trouble brewing for the 2015 npt review conference?\n",
      "\n",
      "area man going to go ahead and consider that a date\n",
      "\n",
      "4 senators mauled during congressional tiger show\n",
      "\n",
      "huffpost hill - secret service agents really glad dark sunglasses hide bloodshot eyes\n",
      "\n",
      "kite flyer in the zone\n",
      "\n",
      "bacon just one of sprint's new downloadable ring scents\n",
      "\n",
      "i photograph to remember\n",
      "\n",
      "u.s. bobsled team pays tribute to late gold medalist steven holcomb\n",
      "\n",
      "among santa fe's many virtues? history, art, culture, hospitality and killer vintage clothing\n",
      "\n",
      "power plan foes from mars, backers from venus (earth actually)\n",
      "\n",
      "journalists who refuse to take the same non-answer for an answer\n",
      "\n",
      "nukes and the global schism\n",
      "\n",
      "weird relative at family reunion knows how everyone related to each other\n",
      "\n",
      "negro week at the 1939–1940 new york world's fair\n",
      "\n",
      "trump threatens to veto spending bill over border wall funding, then signs it\n",
      "\n",
      "6 diy stress hacks using what's in your closet\n",
      "\n",
      "the major concern with the phone call with taiwan\n",
      "\n",
      "a weird and wonderful cabaret chronicle: karen mason revisits her roots at 'don't tell mama!'\n",
      "\n",
      "why companies shouldn't hide the financial risks of climate change\n",
      "\n",
      "the louvre gardens are teeming with rats\n",
      "\n",
      "trump is #1 in the polls, and so was the 'macarena'\n",
      "\n",
      "boy george opens up about happiness, being a u.s. politics junkie and more\n",
      "\n",
      "area woman decides not to post facebook status that would have tipped gun control debate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in data['headline'][600:630]:\n",
    "    print(v + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = [0,1,0,1,1,0,0,0,1,1,1,0,1,1,0,0,0,1,0,1,1,0,0,1,0,0,0,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = data['is_sarcastic'][600:630]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(30-sum(abs(ans-guess)))/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Now Run the Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5610465998370626\n"
     ]
    }
   ],
   "source": [
    "# prior\n",
    "acc = 0\n",
    "k=10\n",
    "for train, test, cross in k_fold_cross_validation(data, k): \n",
    "    confusion_matrix, duration = run_algorithm(train, test, prior)\n",
    "    acc += accuracy(confusion_matrix)\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7730727175082064\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "acc = 0\n",
    "k=10\n",
    "for train, test, cross in k_fold_cross_validation(data, k): \n",
    "    confusion_matrix, duration = run_algorithm(train, test, NB)\n",
    "    acc += accuracy(confusion_matrix)\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483996107897406\n"
     ]
    }
   ],
   "source": [
    "# NB_rank\n",
    "acc = 0\n",
    "k=5\n",
    "for train, test, cross in k_fold_cross_validation(data, k): \n",
    "    confusion_matrix, duration = run_algorithm(train, test, NB_rank)\n",
    "    acc += accuracy(confusion_matrix)\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that worst case scenario, we will get 0.56 accuracy through guessing one value all the time. However, if we use NB, we can achieve an accuracy of around 0.77. This is a C+.\n",
    "\n",
    "If we want to generate headlines, we will want a classifier that does even better. I will arbitrarily set the threshold to 95%. Why? Because when we give NB the opportunity to memorize, it can achieve 96% accuracy.\n",
    "\n",
    "Notice that we are only removing non-alphanumerics and uppercase, but we are not removing things like conjugation for tense or number. We are also not removing stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=list(stopwords.words('english'))[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'shalt',\n",
       " 'thou',\n",
       " 'take',\n",
       " 'holy',\n",
       " 'pin',\n",
       " '.',\n",
       " ',',\n",
       " 'shalt',\n",
       " 'thou',\n",
       " 'count',\n",
       " 'three',\n",
       " ',',\n",
       " ',',\n",
       " 'less',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"First shalt thou take out the Holy Pin. Then, shalt thou count to three, no more, no less.\".lower()\n",
    "[w for w in word_tokenize(sentence) if not w in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers with nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we modify the pipeline so that we exclude the stopwords that the nltk library provides for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_nltk(data,info=None):\n",
    "    values = None\n",
    "    counts = {}\n",
    "    if info is None:\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            for word in entry.split(\" \"):\n",
    "                if not word in stop:\n",
    "                    add_term(counts, word, sarc)\n",
    "        v=list(it.chain(*list(counts.values())))\n",
    "        num_serious_words=sum(v[0::2])\n",
    "        num_sarcastic_words=sum(v[1::2])\n",
    "        for word in counts:\n",
    "            counts[word][0] /= num_serious_words\n",
    "            counts[word][1] /= num_sarcastic_words\n",
    "        values = counts\n",
    "    else:\n",
    "        confusion_matrix = {x:0 for x in it.product([0,1],repeat=2)}\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            # For every headline, multiply the frequency of each word for each class\n",
    "            # If a word in the test set is not found in the training set, ignore it\n",
    "            r = list(it.chain(*[info.get(word, [1,1]) for word in entry.split(\" \")]))\n",
    "            p_serious = reduce((lambda x, y: x * y), r[0::2]) \n",
    "            p_sarcasm = reduce((lambda x, y: x * y), r[1::2]) \n",
    "            result=(p_serious < p_sarcasm, bool(sarc))\n",
    "            confusion_matrix[result] += 1\n",
    "        values = confusion_matrix\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_rank_nltk(data,info=None):\n",
    "    values = None\n",
    "    counts = {}\n",
    "    if info is None:\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            for word in entry.split(\" \"):\n",
    "                if not word in stop:\n",
    "                    add_term(counts, word, sarc)\n",
    "        # Get the ranks of each word in reference to serious\n",
    "        ordered_counts_ser=OrderedDict(sorted(counts.items(), reverse=True, key=lambda x: x[1][0]))\n",
    "        for i,count in enumerate(ordered_counts_ser):\n",
    "            ordered_counts_ser[count][0]=i\n",
    "        # Get the ranks of each word in reference to sarcasm\n",
    "        ordered_counts_sarc=OrderedDict(sorted(ordered_counts_ser.items(), reverse=True, key=lambda x: x[1][1]))\n",
    "        for i,count in enumerate(ordered_counts_sarc):\n",
    "            ordered_counts_sarc[count][1]=i\n",
    "        values = ordered_counts_sarc\n",
    "    else:\n",
    "        confusion_matrix = {x:0 for x in it.product([0,1],repeat=2)}\n",
    "        for entry, sarc in zip(data['headline'],data['is_sarcastic']):\n",
    "            # If a word in the test set is not found in the training set, ignore it\n",
    "            r=list(it.chain(*[info.get(word,[0,0]) for word in entry.split(\" \")]))\n",
    "            # For every headline, add up the rankings of each word for each class\n",
    "            psar = sum(r[1::2])\n",
    "            pser = sum(r[0::2])\n",
    "            result=(pser > psar,bool(sarc))\n",
    "            confusion_matrix[result] += 1\n",
    "        values = confusion_matrix\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74678959892422\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "acc = 0\n",
    "k=10\n",
    "for train, test, cross in k_fold_cross_validation(data, k): # never before seen words\n",
    "    confusion_matrix, duration = run_algorithm(train, test, NB_nltk)\n",
    "    acc += accuracy(confusion_matrix)\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7488487107326999\n"
     ]
    }
   ],
   "source": [
    "# NB_rank\n",
    "acc = 0\n",
    "k=10\n",
    "for train, test, cross in k_fold_cross_validation(data, k): # never before seen words\n",
    "    confusion_matrix, duration = run_algorithm(train, test, NB_rank_nltk)\n",
    "    acc += accuracy(confusion_matrix)\n",
    "print(acc/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that removing the stopwords reduces accuracy, but not by much. This is an interesting finding. Let's see if we can get better accuracy using a neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we shall try to accomplish here is to run the same NLP analysis using a neural network architecture. We shall use keras.\n",
    "\n",
    "The following example is pulled directly from https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e. This is used as a learning opportunity only and is not part of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n",
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('---review---')\n",
    "print(X_train[6])\n",
    "print('---label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "---review with words---\n",
      "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
      "---label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[6]])\n",
    "print('---label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2697\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum review length: 14\n"
     ]
    }
   ],
   "source": [
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeffr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeffr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 293s 12ms/step - loss: 0.4808 - acc: 0.7592 - val_loss: 0.2669 - val_acc: 0.9375\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 284s 11ms/step - loss: 0.3200 - acc: 0.8662 - val_loss: 0.2150 - val_acc: 0.9531\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 285s 11ms/step - loss: 0.2753 - acc: 0.8900 - val_loss: 0.2866 - val_acc: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc09a4ccc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.86732\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
